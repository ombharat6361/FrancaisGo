{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lAPaYF2J8iWj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "763828b9-90bd-4f3d-d4f6-cfe9ca547bbb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['  Installing build dependencies ... \\x1b[?25l\\x1b[?25hdone',\n",
              " '  Getting requirements to build wheel ... \\x1b[?25l\\x1b[?25hdone',\n",
              " '  Preparing metadata (pyproject.toml) ... \\x1b[?25l\\x1b[?25hdone',\n",
              " '\\x1b[?25l     \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/944.9 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K     \\x1b[91m━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m174.1/944.9 kB\\x1b[0m \\x1b[31m4.9 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K     \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m542.7/944.9 kB\\x1b[0m \\x1b[31m8.0 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K     \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m942.1/944.9 kB\\x1b[0m \\x1b[31m9.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K     \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m944.9/944.9 kB\\x1b[0m \\x1b[31m8.7 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25h\\x1b[?25l     \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/6.5 MB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K     \\x1b[91m━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.6/6.5 MB\\x1b[0m \\x1b[31m18.2 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K     \\x1b[91m━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m1.2/6.5 MB\\x1b[0m \\x1b[31m19.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K     \\x1b[91m━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m1.8/6.5 MB\\x1b[0m \\x1b[31m16.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K     \\x1b[91m━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m2.8/6.5 MB\\x1b[0m \\x1b[31m20.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K     \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m4.1/6.5 MB\\x1b[0m \\x1b[31m23.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K     \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━\\x1b[0m \\x1b[32m5.7/6.5 MB\\x1b[0m \\x1b[31m27.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K     \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m6.5/6.5 MB\\x1b[0m \\x1b[31m28.9 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K     \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m6.5/6.5 MB\\x1b[0m \\x1b[31m25.8 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25h  Building wheel for keras-nlp (pyproject.toml) ... \\x1b[?25l\\x1b[?25hdone']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!!pip install -q rouge-score\n",
        "!!pip install -q git+https://github.com/keras-team/keras-nlp.git --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_nlp\n",
        "import pathlib\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow import keras\n",
        "from tensorflow_text.tools.wordpiece_vocab import (\n",
        "    bert_vocab_from_dataset as bert_vocab,\n",
        ")"
      ],
      "metadata": {
        "id": "zJboYzy5-A9M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad5a2423-8f87-47de-8fd0-9254750be54f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 20  # This should be at least 10 for convergence\n",
        "MAX_SEQUENCE_LENGTH = 40\n",
        "ENG_VOCAB_SIZE = 15000\n",
        "ORI_VOCAB_SIZE = 15000\n",
        "\n",
        "EMBED_DIM = 256\n",
        "INTERMEDIATE_DIM = 2048\n",
        "NUM_HEADS = 8"
      ],
      "metadata": {
        "id": "PT00_EGd-DaS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.manythings.org/anki/fra-eng.zip"
      ],
      "metadata": {
        "id": "17jaCxgl-0iM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dcd24be-ca96-4885-b781-25b632f190e0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-20 16:30:23--  https://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7757635 (7.4M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip’\n",
            "\n",
            "fra-eng.zip         100%[===================>]   7.40M  35.4MB/s    in 0.2s    \n",
            "\n",
            "2023-09-20 16:30:23 (35.4 MB/s) - ‘fra-eng.zip’ saved [7757635/7757635]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip fra-eng.zip"
      ],
      "metadata": {
        "id": "_anxyvCQ_FHd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ab51062-b4bc-4a7d-ee39-008482525ba7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  fra-eng.zip\n",
            "  inflating: _about.txt              \n",
            "  inflating: fra.txt                 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_file = 'fra.txt'\n",
        "os.remove('_about.txt')\n",
        "os.remove('fra-eng.zip')"
      ],
      "metadata": {
        "id": "2IJFm3Ek_AN9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(text_file) as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "text_pairs = []\n",
        "for line in lines:\n",
        "    eng = line.split(\"\\t\")[0]\n",
        "    ori = line.split(\"\\t\")[1]\n",
        "    eng = eng.lower()\n",
        "    ori = ori.lower()\n",
        "    text_pairs.append((eng, ori))"
      ],
      "metadata": {
        "id": "A2juwgly-Pas"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(5):\n",
        "    print(random.choice(text_pairs))"
      ],
      "metadata": {
        "id": "HWg9LdhS_fYx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c3e606c-f6ad-4bda-e41e-b977a079f0fa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(\"the app won't work if you're not connected to the internet.\", \"l'appli ne marchera pas si tu n'es pas connecté à internet.\")\n",
            "('they were watching television.', 'ils regardaient la télévision.')\n",
            "(\"i'm not sure i'm ready for that.\", \"je ne suis pas certain d'être prêt pour cela.\")\n",
            "(\"you're to blame for the accident.\", \"vous êtes responsable de l'accident.\")\n",
            "(\"here's what you should do.\", 'voilà ce que tu devrais faire.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
        "\n",
        "print(f\"{len(text_pairs)} total pairs\")\n",
        "print(f\"{len(train_pairs)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")\n",
        "print(f\"{len(test_pairs)} test pairs\")"
      ],
      "metadata": {
        "id": "qfARaNYcAD9i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3168b7af-ffdf-464a-f78c-ba7f421ef6f9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "227815 total pairs\n",
            "159471 training pairs\n",
            "34172 validation pairs\n",
            "34172 test pairs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_word_piece(text_samples, vocab_size, reserved_tokens):\n",
        "    word_piece_ds = tf.data.Dataset.from_tensor_slices(text_samples)\n",
        "    vocab = keras_nlp.tokenizers.compute_word_piece_vocabulary(\n",
        "        word_piece_ds.batch(1000).prefetch(2),\n",
        "        vocabulary_size=vocab_size,\n",
        "        reserved_tokens=reserved_tokens,\n",
        "    )\n",
        "    return vocab"
      ],
      "metadata": {
        "id": "Xay50mBUAGeX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reserved_tokens = [\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n",
        "\n",
        "eng_samples = [text_pair[0] for text_pair in train_pairs]\n",
        "eng_vocab = train_word_piece(eng_samples, ENG_VOCAB_SIZE, reserved_tokens)\n",
        "\n",
        "ori_samples = [text_pair[1] for text_pair in train_pairs]\n",
        "ori_vocab = train_word_piece(ori_samples, ORI_VOCAB_SIZE, reserved_tokens)"
      ],
      "metadata": {
        "id": "xcqmY4X5AJNN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(vocabulary=eng_vocab, lowercase=False)\n",
        "ori_tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(vocabulary=ori_vocab, lowercase=False)"
      ],
      "metadata": {
        "id": "euD0ECDBAK85"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_input_ex = text_pairs[0][0]\n",
        "eng_tokens_ex = eng_tokenizer.tokenize(eng_input_ex)\n",
        "print(\"English sentence: \", eng_input_ex)\n",
        "print(\"Tokens: \", eng_tokens_ex)\n",
        "print(\"Recovered text after detokenizing: \",\n",
        "    eng_tokenizer.detokenize(eng_tokens_ex),)\n",
        "\n",
        "print()\n",
        "\n",
        "ori_input_ex = text_pairs[0][1]\n",
        "ori_tokens_ex = ori_tokenizer.tokenize(ori_input_ex)\n",
        "print(\"Oriya sentence: \", ori_input_ex)\n",
        "print(\"Tokens: \", ori_tokens_ex)\n",
        "print(\n",
        "    \"Recovered text after detokenizing: \",\n",
        "    ori_tokenizer.detokenize(ori_tokens_ex),\n",
        ")"
      ],
      "metadata": {
        "id": "Ivz5w3EuAm9D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17896acd-f393-4417-b19b-c84c5b1e6cdc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English sentence:  i owe him 1,000 dollars.\n",
            "Tokens:  tf.Tensor([  36  877  111   16   11 1469  814   13], shape=(8,), dtype=int32)\n",
            "Recovered text after detokenizing:  tf.Tensor(b'i owe him 1 , 000 dollars .', shape=(), dtype=string)\n",
            "\n",
            "Oriya sentence:  je lui dois 1 000 dollars.\n",
            "Tokens:  tf.Tensor([  79  149  195   18 2415  778   15], shape=(7,), dtype=int32)\n",
            "Recovered text after detokenizing:  tf.Tensor(b'je lui dois 1 000 dollars .', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_batch(eng, ori):\n",
        "    batch_size = tf.shape(ori)[0]\n",
        "\n",
        "    eng = eng_tokenizer(eng)\n",
        "    ori = ori_tokenizer(ori)\n",
        "\n",
        "    # Pad `eng` to `MAX_SEQUENCE_LENGTH`.\n",
        "    eng_start_end_packer = keras_nlp.layers.StartEndPacker(\n",
        "        sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "        pad_value=eng_tokenizer.token_to_id(\"[PAD]\"),\n",
        "    )\n",
        "    eng = eng_start_end_packer(eng)\n",
        "\n",
        "    # Add special tokens (`\"[START]\"` and `\"[END]\"`) to `ori` and pad it as well.\n",
        "    ori_start_end_packer = keras_nlp.layers.StartEndPacker(\n",
        "        sequence_length=MAX_SEQUENCE_LENGTH + 1,\n",
        "        start_value=ori_tokenizer.token_to_id(\"[START]\"),\n",
        "        end_value=ori_tokenizer.token_to_id(\"[END]\"),\n",
        "        pad_value=ori_tokenizer.token_to_id(\"[PAD]\"),\n",
        "    )\n",
        "    ori = ori_start_end_packer(ori)\n",
        "\n",
        "    return (\n",
        "        {\n",
        "            \"encoder_inputs\": eng,\n",
        "            \"decoder_inputs\": ori[:, :-1],\n",
        "        },\n",
        "        ori[:, 1:],\n",
        "    )\n",
        "\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, ori_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    ori_texts = list(ori_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, ori_texts))\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.map(preprocess_batch, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ],
      "metadata": {
        "id": "zmtecFdkA1_W"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ],
      "metadata": {
        "id": "3kPfQAI2BNG2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18459481-f880-4683-c5fe-04569c48d1c0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (64, 40)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 40)\n",
            "targets.shape: (64, 40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "\n",
        "x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "    vocabulary_size=ENG_VOCAB_SIZE,\n",
        "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "    embedding_dim=EMBED_DIM,\n",
        "    mask_zero=True,\n",
        ")(encoder_inputs)\n",
        "\n",
        "encoder_outputs = keras_nlp.layers.TransformerEncoder(\n",
        "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
        ")(inputs=x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, EMBED_DIM), name=\"decoder_state_inputs\")\n",
        "\n",
        "x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "    vocabulary_size=ORI_VOCAB_SIZE,\n",
        "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "    embedding_dim=EMBED_DIM,\n",
        "    mask_zero=True,\n",
        ")(decoder_inputs)\n",
        "\n",
        "x = keras_nlp.layers.TransformerDecoder(\n",
        "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
        ")(decoder_sequence=x, encoder_sequence=encoded_seq_inputs)\n",
        "x = keras.layers.Dropout(0.5)(x)\n",
        "decoder_outputs = keras.layers.Dense(ORI_VOCAB_SIZE, activation=\"softmax\")(x)\n",
        "decoder = keras.Model(\n",
        "    [\n",
        "        decoder_inputs,\n",
        "        encoded_seq_inputs,\n",
        "    ],\n",
        "    decoder_outputs,\n",
        ")\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "\n",
        "transformer = keras.Model(\n",
        "    [encoder_inputs, decoder_inputs],\n",
        "    decoder_outputs,\n",
        "    name=\"transformer\",\n",
        ")"
      ],
      "metadata": {
        "id": "Xn-0XXMvBRpp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.summary()\n",
        "transformer.compile(\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "61f985khBbx-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c21d2c8a-f23a-4542-ac4a-b61082366823"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer  [(None, None)]               0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " token_and_position_embeddi  (None, None, 256)            3850240   ['encoder_inputs[0][0]']      \n",
            " ng (TokenAndPositionEmbedd                                                                       \n",
            " ing)                                                                                             \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer  [(None, None)]               0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " transformer_encoder (Trans  (None, None, 256)            1315072   ['token_and_position_embedding\n",
            " formerEncoder)                                                     [0][0]']                      \n",
            "                                                                                                  \n",
            " model_1 (Functional)        (None, None, 15000)          9283992   ['decoder_inputs[0][0]',      \n",
            "                                                                     'transformer_encoder[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 14449304 (55.12 MB)\n",
            "Trainable params: 14449304 (55.12 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.fit(train_ds, epochs=EPOCHS, validation_data=val_ds)"
      ],
      "metadata": {
        "id": "kflkmJsrBfFh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68ba8759-f7be-4161-c38b-997a9bb4af0b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "2492/2492 [==============================] - 240s 91ms/step - loss: 2.6726 - accuracy: 0.5676 - val_loss: 1.9148 - val_accuracy: 0.6641\n",
            "Epoch 2/20\n",
            "2492/2492 [==============================] - 184s 74ms/step - loss: 1.9015 - accuracy: 0.6703 - val_loss: 1.6675 - val_accuracy: 0.7025\n",
            "Epoch 3/20\n",
            "2492/2492 [==============================] - 183s 74ms/step - loss: 1.7073 - accuracy: 0.7007 - val_loss: 1.5890 - val_accuracy: 0.7159\n",
            "Epoch 4/20\n",
            "2492/2492 [==============================] - 183s 73ms/step - loss: 1.6113 - accuracy: 0.7172 - val_loss: 1.5532 - val_accuracy: 0.7264\n",
            "Epoch 5/20\n",
            "2492/2492 [==============================] - 182s 73ms/step - loss: 1.5514 - accuracy: 0.7284 - val_loss: 1.5278 - val_accuracy: 0.7333\n",
            "Epoch 6/20\n",
            "2492/2492 [==============================] - 183s 73ms/step - loss: 1.5045 - accuracy: 0.7369 - val_loss: 1.5299 - val_accuracy: 0.7348\n",
            "Epoch 7/20\n",
            "2492/2492 [==============================] - 182s 73ms/step - loss: 1.4650 - accuracy: 0.7446 - val_loss: 1.5200 - val_accuracy: 0.7366\n",
            "Epoch 8/20\n",
            "2492/2492 [==============================] - 183s 73ms/step - loss: 1.4296 - accuracy: 0.7507 - val_loss: 1.5139 - val_accuracy: 0.7415\n",
            "Epoch 9/20\n",
            "2492/2492 [==============================] - 183s 73ms/step - loss: 1.3987 - accuracy: 0.7566 - val_loss: 1.5112 - val_accuracy: 0.7412\n",
            "Epoch 10/20\n",
            "2492/2492 [==============================] - 183s 73ms/step - loss: 1.3698 - accuracy: 0.7616 - val_loss: 1.5006 - val_accuracy: 0.7467\n",
            "Epoch 11/20\n",
            "2492/2492 [==============================] - 183s 73ms/step - loss: 1.3446 - accuracy: 0.7660 - val_loss: 1.5094 - val_accuracy: 0.7470\n",
            "Epoch 12/20\n",
            "2492/2492 [==============================] - 183s 73ms/step - loss: 1.3217 - accuracy: 0.7705 - val_loss: 1.5119 - val_accuracy: 0.7474\n",
            "Epoch 13/20\n",
            "2492/2492 [==============================] - 182s 73ms/step - loss: 1.2981 - accuracy: 0.7745 - val_loss: 1.5158 - val_accuracy: 0.7475\n",
            "Epoch 14/20\n",
            "2492/2492 [==============================] - 203s 81ms/step - loss: 1.2778 - accuracy: 0.7780 - val_loss: 1.5254 - val_accuracy: 0.7477\n",
            "Epoch 15/20\n",
            "2492/2492 [==============================] - 183s 73ms/step - loss: 1.2583 - accuracy: 0.7816 - val_loss: 1.5180 - val_accuracy: 0.7504\n",
            "Epoch 16/20\n",
            "2492/2492 [==============================] - 183s 73ms/step - loss: 1.2407 - accuracy: 0.7850 - val_loss: 1.5185 - val_accuracy: 0.7508\n",
            "Epoch 17/20\n",
            "2492/2492 [==============================] - 203s 81ms/step - loss: 1.2241 - accuracy: 0.7879 - val_loss: 1.5314 - val_accuracy: 0.7510\n",
            "Epoch 18/20\n",
            "2492/2492 [==============================] - 183s 74ms/step - loss: 1.2099 - accuracy: 0.7905 - val_loss: 1.5406 - val_accuracy: 0.7520\n",
            "Epoch 19/20\n",
            "2492/2492 [==============================] - 183s 73ms/step - loss: 1.1939 - accuracy: 0.7932 - val_loss: 1.5332 - val_accuracy: 0.7530\n",
            "Epoch 20/20\n",
            "2492/2492 [==============================] - 203s 82ms/step - loss: 1.1805 - accuracy: 0.7958 - val_loss: 1.5612 - val_accuracy: 0.7523\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fd5d1fe90c0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequences(input_sentences):\n",
        "    batch_size = tf.shape(input_sentences)[0]\n",
        "\n",
        "    # Tokenize the encoder input.\n",
        "    encoder_input_tokens = eng_tokenizer(input_sentences).to_tensor(\n",
        "        shape=(None, MAX_SEQUENCE_LENGTH)\n",
        "    )\n",
        "\n",
        "    # Define a function that outputs the next token's probability given the\n",
        "    # input sequence.\n",
        "    def next(prompt, cache, index):\n",
        "        logits = transformer([encoder_input_tokens, prompt])[:, index - 1, :]\n",
        "        # Ignore hidden states for now; only needed for contrastive search.\n",
        "        hidden_states = None\n",
        "        return logits, hidden_states, cache\n",
        "\n",
        "    # Build a prompt of length 40 with a start token and padding tokens.\n",
        "    length = 40\n",
        "    start = tf.fill((batch_size, 1), ori_tokenizer.token_to_id(\"[START]\"))\n",
        "    pad = tf.fill((batch_size, length - 1), ori_tokenizer.token_to_id(\"[PAD]\"))\n",
        "    prompt = tf.concat((start, pad), axis=-1)\n",
        "\n",
        "    generated_tokens = keras_nlp.samplers.GreedySampler()(\n",
        "        next,\n",
        "        prompt,\n",
        "        end_token_id=ori_tokenizer.token_to_id(\"[END]\"),\n",
        "        index=1,  # Start sampling after start token.\n",
        "    )\n",
        "    generated_sentences = ori_tokenizer.detokenize(generated_tokens)\n",
        "    return generated_sentences\n",
        "\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "for i in range(2):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    translated = decode_sequences(tf.constant([input_sentence]))\n",
        "    translated = translated.numpy()[0].decode(\"utf-8\")\n",
        "    translated = (\n",
        "        translated.replace(\"[PAD]\", \"\")\n",
        "        .replace(\"[START]\", \"\")\n",
        "        .replace(\"[END]\", \"\")\n",
        "        .strip()\n",
        "    )\n",
        "    print(f\"** Example {i} **\")\n",
        "    print(input_sentence)\n",
        "    print(translated)\n",
        "    print()"
      ],
      "metadata": {
        "id": "14qtRlIBBlnP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f43c6ecc-62fb-4241-95fd-2cc99ec7c88c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "** Example 0 **\n",
            "i've always admired you enormously.\n",
            "je vous ai toujours admirélaré .\n",
            "\n",
            "** Example 1 **\n",
            "since i haven't received an answer, i was wondering if maybe my mail never got delivered to you.\n",
            "comme je n ' ai pas reçu une réponse , j ' ai eu un mémoidé s ' est fait , j ' ai été donné de la moindre de la réponse à ne de\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lh7lr4BjCfyh"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}